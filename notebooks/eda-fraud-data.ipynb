{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA for Fraud_Data.csv\n",
        "\n",
        "This notebook performs exploratory data analysis on the e-commerce fraud detection dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "from data_cleaning import clean_fraud_data, ip_to_integer, merge_ip_to_country\n",
        "from feature_engineering import create_time_features, create_transaction_frequency_features\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Load data\n",
        "print(\"Loading Fraud_Data.csv...\")\n",
        "fraud_df = pd.read_csv('../data/raw/Fraud_Data.csv')\n",
        "print(f\"Shape: {fraud_df.shape}\")\n",
        "print(f\"\\nColumns: {fraud_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "fraud_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean the data\n",
        "fraud_df_clean = clean_fraud_data(fraud_df)\n",
        "\n",
        "# Display basic info\n",
        "print(\"Data Info:\")\n",
        "print(fraud_df_clean.info())\n",
        "print(\"\\nData Types:\")\n",
        "print(fraud_df_clean.dtypes)\n",
        "print(\"\\nBasic Statistics:\")\n",
        "fraud_df_clean.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Univariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Count plot\n",
        "class_counts = fraud_df_clean['class'].value_counts()\n",
        "axes[0].bar(class_counts.index, class_counts.values, color=['green', 'red'])\n",
        "axes[0].set_xlabel('Class (0=Legitimate, 1=Fraud)')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Class Distribution')\n",
        "axes[0].set_xticks([0, 1])\n",
        "\n",
        "# Percentage\n",
        "class_pct = fraud_df_clean['class'].value_counts(normalize=True) * 100\n",
        "axes[1].bar(class_pct.index, class_pct.values, color=['green', 'red'])\n",
        "axes[1].set_xlabel('Class (0=Legitimate, 1=Fraud)')\n",
        "axes[1].set_ylabel('Percentage')\n",
        "axes[1].set_title('Class Distribution (%)')\n",
        "axes[1].set_xticks([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Class distribution:\")\n",
        "print(fraud_df_clean['class'].value_counts())\n",
        "print(f\"\\nClass imbalance ratio: {class_counts[0] / class_counts[1]:.2f}:1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of numerical features\n",
        "numerical_cols = ['purchase_value', 'age']\n",
        "fig, axes = plt.subplots(1, len(numerical_cols), figsize=(15, 5))\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    if col in fraud_df_clean.columns:\n",
        "        axes[i].hist(fraud_df_clean[col].dropna(), bins=50, edgecolor='black')\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].set_title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of categorical features\n",
        "categorical_cols = ['source', 'browser', 'sex']\n",
        "fig, axes = plt.subplots(1, len(categorical_cols), figsize=(18, 5))\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    if col in fraud_df_clean.columns:\n",
        "        value_counts = fraud_df_clean[col].value_counts()\n",
        "        axes[i].bar(range(len(value_counts)), value_counts.values)\n",
        "        axes[i].set_xticks(range(len(value_counts)))\n",
        "        axes[i].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
        "        axes[i].set_ylabel('Count')\n",
        "        axes[i].set_title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Bivariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purchase value by class\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Box plot\n",
        "fraud_df_clean.boxplot(column='purchase_value', by='class', ax=axes[0])\n",
        "axes[0].set_title('Purchase Value by Class')\n",
        "axes[0].set_xlabel('Class')\n",
        "axes[0].set_ylabel('Purchase Value')\n",
        "\n",
        "# Violin plot\n",
        "sns.violinplot(data=fraud_df_clean, x='class', y='purchase_value', ax=axes[1])\n",
        "axes[1].set_title('Purchase Value Distribution by Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical summary\n",
        "print(\"Purchase Value Statistics by Class:\")\n",
        "print(fraud_df_clean.groupby('class')['purchase_value'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age by class\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Box plot\n",
        "fraud_df_clean.boxplot(column='age', by='class', ax=axes[0])\n",
        "axes[0].set_title('Age by Class')\n",
        "axes[0].set_xlabel('Class')\n",
        "axes[0].set_ylabel('Age')\n",
        "\n",
        "# Violin plot\n",
        "sns.violinplot(data=fraud_df_clean, x='class', y='age', ax=axes[1])\n",
        "axes[1].set_title('Age Distribution by Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical summary\n",
        "print(\"Age Statistics by Class:\")\n",
        "print(fraud_df_clean.groupby('class')['age'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud rate by categorical features\n",
        "categorical_cols = ['source', 'browser', 'sex']\n",
        "fig, axes = plt.subplots(1, len(categorical_cols), figsize=(18, 5))\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    if col in fraud_df_clean.columns:\n",
        "        fraud_rate = fraud_df_clean.groupby(col)['class'].mean() * 100\n",
        "        axes[i].bar(range(len(fraud_rate)), fraud_rate.values)\n",
        "        axes[i].set_xticks(range(len(fraud_rate)))\n",
        "        axes[i].set_xticklabels(fraud_rate.index, rotation=45, ha='right')\n",
        "        axes[i].set_ylabel('Fraud Rate (%)')\n",
        "        axes[i].set_title(f'Fraud Rate by {col}')\n",
        "        axes[i].axhline(y=fraud_df_clean['class'].mean() * 100, color='r', linestyle='--', label='Overall Average')\n",
        "        axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Geolocation Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load IP to Country mapping\n",
        "print(\"Loading IpAddress_to_Country.csv...\")\n",
        "ip_country_df = pd.read_csv('../data/raw/IpAddress_to_Country.csv')\n",
        "print(f\"Shape: {ip_country_df.shape}\")\n",
        "print(f\"\\nColumns: {ip_country_df.columns.tolist()}\")\n",
        "ip_country_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert IP address columns to integer\n",
        "ip_country_df['lower_bound_ip_address'] = ip_country_df['lower_bound_ip_address'].apply(ip_to_integer)\n",
        "ip_country_df['upper_bound_ip_address'] = ip_country_df['upper_bound_ip_address'].apply(ip_to_integer)\n",
        "\n",
        "# Merge fraud data with country mapping\n",
        "fraud_df_with_country = merge_ip_to_country(fraud_df_clean, ip_country_df)\n",
        "print(f\"Shape after merge: {fraud_df_with_country.shape}\")\n",
        "print(f\"Rows matched: {len(fraud_df_with_country)} / {len(fraud_df_clean)}\")\n",
        "\n",
        "fraud_df_with_country.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze fraud patterns by country\n",
        "if 'country' in fraud_df_with_country.columns:\n",
        "    country_fraud = fraud_df_with_country.groupby('country').agg({\n",
        "        'class': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    country_fraud.columns = ['country', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "    country_fraud = country_fraud.sort_values('fraud_rate', ascending=False)\n",
        "    \n",
        "    # Top 20 countries by fraud rate\n",
        "    top_countries = country_fraud.head(20)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "    \n",
        "    # Fraud rate\n",
        "    axes[0].barh(range(len(top_countries)), top_countries['fraud_rate'].values)\n",
        "    axes[0].set_yticks(range(len(top_countries)))\n",
        "    axes[0].set_yticklabels(top_countries['country'])\n",
        "    axes[0].set_xlabel('Fraud Rate')\n",
        "    axes[0].set_title('Top 20 Countries by Fraud Rate')\n",
        "    axes[0].invert_yaxis()\n",
        "    \n",
        "    # Total fraud count\n",
        "    top_by_count = country_fraud.sort_values('fraud_count', ascending=False).head(20)\n",
        "    axes[1].barh(range(len(top_by_count)), top_by_count['fraud_count'].values)\n",
        "    axes[1].set_yticks(range(len(top_by_count)))\n",
        "    axes[1].set_yticklabels(top_by_count['country'])\n",
        "    axes[1].set_xlabel('Total Fraud Count')\n",
        "    axes[1].set_title('Top 20 Countries by Total Fraud Count')\n",
        "    axes[1].invert_yaxis()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Top 10 Countries by Fraud Rate:\")\n",
        "    print(country_fraud.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Key Insights\n",
        "\n",
        "Key findings from the EDA:\n",
        "1. Class imbalance ratio\n",
        "2. Important features for fraud detection\n",
        "3. Patterns in fraudulent transactions\n",
        "4. Country-level fraud patterns\n",
        "is"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
